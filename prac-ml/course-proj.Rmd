---
title: "ML Course Project"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

download the data

```{r}
train_url <- "https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv"
test_url <- "https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv"

train_filename <- "pml-training.csv"
test_filename <- "pml-testing.csv"

curl::curl_download(train_url, train_filename)
curl::curl_download(test_url, test_filename)
```


load training data

```{r}
library(tidyverse)
library(caret)
library(doParallel)

training <- read_csv(train_filename)

```
Data Cleaning / EDA

```{r}
training %>% dim()

```
We have a large data set, over 19k rows and 160 variables

lets look at the distribution of the variable we are going to be predicting


```{r}
training %>%
        select(classe) %>%
        table()

```

we have an even spread amount of each class

lets loot at what the first 10 variables

```{r}
training %>%
        select(1:10) %>%
        summary()
```

i'm not going to be using variables 1 to 7 for prediction to i will drop those.
also converting classe to factor and all the other variables to numeric


```{r}
training_clean <- training %>%
        select(-c(1:7)) %>%
        mutate(classe = as_factor(classe)) %>%
        mutate_if(sapply(.,is.character), as.numeric)

```


lets find out about what NA we have

```{r}
training_clean %>%
        select(-classe) %>%
        pivot_longer(everything()) %>%
        group_by(name) %>%
        filter(value %>% is.na) %>%
        summarise(count = n())
```
well, that 100 variables with almost entirely NA, i'll drop them


```{r}
na_cols <-  training_clean %>%
        select(-classe) %>%
        pivot_longer(everything()) %>%
        group_by(name) %>%
        filter(value %>% is.na) %>%
        summarise(count = n()) %>%
        pivot_wider(names_from = name, values_from = count)
        

names(na_cols)

training_clean <- training_clean %>% select(-names(na_cols))

```


Instead of fitting all rows, pick a random sample of about half of them

set up pre-processing to normalize then apply it to the training sample

```{r}
#draw sample for quick fitting and testing preprocessing
set.seed(123)
sample <- sample_n(training_clean, 8000)

preProcSample = preProcess(sample, 
                           method = c("center", "scale"))

sample_trans <- predict(preProcSample, sample)


```


cross validation to estimate out of sample error.

10 fold cross validation with 10 repeats

```{r}

trainControl <- trainControl(method = "repeatedcv",
                          number = 10,
                          repeats = 10,
                          allowParallel = TRUE)

```

Going to use a random forest model, doParallel speeds things up

```{r, cache=TRUE}
no_cores = detectCores() -1
cl <- makePSOCKcluster(no_cores)
registerDoParallel(cl)


mod_tree <- train(
                  classe ~ ., 
                  method = "rf", 
                  data = sample_trans,
                  trControl = trainControl
                  )

stopCluster(cl)

#save the model
saveRDS(mod_tree, file = "second_mod_tree")

mod_tree

```

I estimate my out of sample accuracy to be 98.5% with mtry = 27

i'll use this to prediction for the quiz

```{r}
#read data
testing <- read_csv(test_filename)

#preProcess data
testing_clean <-  testing %>%
        select(-c(1:7)) %>%
        mutate_if(sapply(.,is.character), as.numeric)

#remove NA cols
testing_clean <- testing_clean %>% select(-names(na_cols))

testing_processed <- predict(preProcSample, testing_clean)

predict(mod_tree, testing_processed) %>%
        as_tibble() %>%
        mutate(row_num = row_number()) %>%
        select(row_num, value)


```

Result of the Quiz was 100%


































